# -*- coding: utf-8 -*-
"""Rock and Mine Prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mn3fdTn9-1QFYqsfNvl2Qws2iAGHdKjF

PROJECT NAME : ROCK AND MINE PREDICTION
"""

# ROCK AND MINE PREDICTION
# we will create a model using sonar data which will help
# the submarine to predict whether the object is mine or rock.

"""Importing The Dependencies"""

# Importing the libraries and dependencies
import numpy as np # numpy for arrays
import pandas as pd # pandas for data processing steps ,it will load our data into table called dataframes
from sklearn.model_selection import train_test_split # Now to train and test our data we need sklearn function so will not done it manually
from sklearn.linear_model import LogisticRegression # Now to import logictic regression algorithm for opur model
from sklearn.metrics import accuracy_score # import accuracy_score function to check the accuracy of our model

"""Data Collection And Data Preprocessing"""

# Loading the dataset into the pandas dataframe
# we will create a variable which represent dataframe named sonar_data
sonar_data=pd.read_csv('/content/sonar data.csv',header=None)         # so, pd for pandas ,our file is in csv so read_csv is used then filepath then as our file
#  don't have name for particular column so we will mention that header files are not exit

# Now to display first five rows of our dataset we will use head function
sonar_data.head()

#  Now to find the no. of rows and columns in  the data we will use shape function
sonar_data.shape
#  208 rows means there are 208 examples or instances of data

#  describe() function helps to get some statistical data like count,mean,percentage of components
sonar_data.describe()

# to identify how many examples of rock and mine are there in the data we will use value.counts() function
#  for this and as in our data in 60th column it is represented as R for rocks and M for mines .so pass 60 in the code .
sonar_data[60].value_counts()

"""SO , mines are 111 and rocks are 97 so, they are almost equal so it will be good for us to prepare a good model"""

# now we will group our data into rock and mine by using groupby.mean(), and also pass 60 as 60th columns denotes the R and M.
sonar_data.groupby(60).mean()

"""Here , are the mean values of every mine and rock example for 60 columns .
As we can see the diference between mine and rock values is very little .
But this difference is quite important as this difference will be used to identify whether the object is rock or a mine

THIS is SUPERVISED LEARNING . SO, we train our model with data and label . But, In UNSUPERVISED LEARNING we don't have labels
"""

# separating the data (Numerical values) and the label (60th column representing R and M )
#  now we remember to drop the column then axis is 1 and when we drop a row then axis is 0
X=sonar_data.drop(columns=60,axis=1)  # dropping 60th column means storing all the values except 60th column in variable X
Y=sonar_data[60] # storing 60th column into Y variable

print(X)
print(Y)

"""We splitted the data and the label . Now we will train and test this data  by using train_test_split this function



"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,stratify=Y,random_state=1)

"""X_train is a training data
Y_train is a label of that training data
X_test is a testing data
Y_test is a label of that training data

Then , we use train_test_split function to split my data

Then , we give parameters X AND Y  because we want to split our data into these X and Y .

test_size=0.1 it means that we are reserving some data for test data . if suppose 200 examples are there in a data then 0.1 % of 200 be 20 so 20 examples of the data will be reserved for checking later

STRATIFY = Y  it means that we have to split our data to identify the label .So, Y contains the last column or label column that'swhy we have to pass Y to  stratify it accordingly .

random_state=1 it increase randomness
"""

#  shape functionn is used to identify the vales
print(X.shape,X_train.shape,X_test.shape)

# print the training data and training data label separately
print(X_train)
print(Y_train)

"""So, here (208,60) total data
(187,60) training data
(21,60) testing data

So, we have to train our ml model with this training data
"""

#   WE WILL TRAIN OUR MODEL BY USINF LOGISTIC REGRESSION ALGORITHM
# CREATE A FUNCTION NAMED model
model=LogisticRegression()

"""WE LOAD THE LOGISTIC REGREESSION FUNCTION INTO THIS model variable to use further"""

#  TRAINING THE LOGISTIC REGRESSION MODEL WITH TRAINING DATA
# Now , we willl fit our training data and training data label into our model
model.fit(X_train,Y_train)

"""Now we will check accuracy score to see how our model is predicting"""

# MODEL EVALUATION
#  we need to test our data for accuracy on training data
# So, first we will find the accuracy of training data  and testing data

"""HERE THE SIGNIFICANCE is we saw the training data but we don't saw the test data . ACCURACY for training data will be more because model see the training data and accuracy for testing data will be less because model don't see the test data .
If we use more data for our model then our accuracy will be good
HERE , OUR DATA is less so , might be our model has somewhat low accuracy
Any accuracy which is greater than 70 is good


"""

# Accuracy of training data
X_train_prediction=model.predict(X_train)
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

"""So, here we are predicting the training data
and then we are finding the accuracy of the training data
X_train_prediction is the extreme prediction of our model for the training data
and Y_train is the real answer of the data .
So, we are going to compare prediction of our model and original label/real answer Y_train
 of these data to get the accuracy .
"""

# print accuracy of our training data
print('Accuracy on training data: ',training_data_accuracy)

"""So ,  83. 4  is accuracy score which is very  good for this training
data
"""

# now we will find accuracy score for test data
#  So, our model don't see this test data

X_test_prediction=model.predict(X_test)
testing_data_accuracy=accuracy_score(X_test_prediction,Y_test)

"""So, here we are predicting the testing data and then we are finding the accuracy of the testing data X_test_prediction is the extreme prediction of our model for the testing data and Y_test
 is the real answer of the data . So, we are going to compare prediction of our model and original label of these data to get the accuracy .
"""

# print accuracy of our testing data
print('Accuracy on testing data: ',testing_data_accuracy)

"""So , 76.19 is accuracy score which is very good for this testing data.
Here, it means out of 100 times it will predict 76 times correct that whether the object is rock or a mine

Now , we have trained logistic regression model
and now we are going to make a predictive system that will predict whther the object is rock or a mine
"""

#  MAKING A PREDICTIVE SYSTEM
# FIRST  we will give the input data of our sonar data and then we will give some
#  examples of a rock and a mine to this system then we will check our system is predicting correct or not

"""1.After taking some input data have to import the numpy array to convert that data into numpy array because the processing of numpy array is faster and easy.

2.Now we have to reshape the array as we are only taking one row or one instance which has 60 columns so our model will be confused.

3.so array.reshape(1,-1) here this 1,-1 represent that we taking only one instance or one row .So, we are finding the label for that one instance

4.Now we will make a prediction which will check our predictive system it will predict whether the data is a rock or a mine

5.the correct answer is a rock
"""

# create a input data named variable in which we will give some random sonar data which is a rock
# if model predict that it is a rock then our model will be working fine
input_data=(0.0365,0.1632,0.1636,0.1421,0.1130,0.1306,0.2112,0.2268,0.2992,0.3735,0.3042,0.0387,0.2679,0.5397,0.6204,0.7257,0.8350,0.6888,0.4450,0.3921,0.5605,0.7545,0.8311,1.0000,0.8762,0.7092,0.7009,0.5014,0.3942,0.4456,0.4072,0.0773,0.1423,0.0401,0.3597,0.6847,0.7076,0.3597,0.0612,0.3027,0.3966,0.3868,0.2380,0.2059,0.2288,0.1704,0.1587,0.1792,0.1022,0.0151,0.0223,0.0110,0.0071,0.0205,0.0164,0.0063,0.0078,0.0094,0.0110,0.0068)
# changing the datatype of input_data from a list to a numpy array
# asarray function is used to convert datatype to array
input_data_as_numpy_array=np.asarray(input_data)
input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)

# Now we will make a prediction which will check our predictive system it will predict whether the data is a rock or a mine
# the correct answer is a rock
prediction=model.predict(input_data_reshaped)
print(prediction)
if(prediction[0]=='R'):
  print('The object is a Rock')
else:
  print('The object is a Mine')

"""so, the data is for a rock and the answer show the correct label 'R'"""

